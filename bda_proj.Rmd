---
title: 'MATH 264: Bayesian Project'
output:
  html_document: default
  html_notebook: default
---

```{r, echo = FALSE}
## Reading in datasets for the analysis

## Death count data (Quentin Taratino movies removed)
dc <- read.csv("filmdeathcounts_no-qt.csv", 
               header = TRUE, 
               stringsAsFactors = FALSE)

## Project dataset meta data
qt <- read.table("qt_data.txt", 
                 header = FALSE, 
                 col.names = c("movie", "body.count", "rating", "hours", "year", "genre"),
                 sep = ";",
                 strip.white = TRUE,
                 stringsAsFactors = FALSE)
```

### Data Summary

```{r, echo = FALSE}
qt[,c(1,2,4)]
cat("Body count summary:", fill = TRUE)
summary(qt$body.count)
cat("Sample variance:", var(qt$body.count), "\n", fill = TRUE)
cat("Body count (exclude outlier) summary:", fill = TRUE)
summary(qt$body.count[qt$body.count != max(qt$body.count)])
cat("Sample variance:", var(qt$body.count[qt$body.count != max(qt$body.count)]), "\n", fill = TRUE)
cat("Movie duration summary:", fill = TRUE)
summary(qt$hours)
```

Regardless of whether the large outlier is included, the sample mean and sample variance differ significantly. This suggests the Poisson model may not be a very good fit

### Sampling Distribution: Poisson with rate and exposure

According to Gelman et. al. (pg. 45), this model is NOT exchangeable in the $y_i$'s but is exchangeable in the pairs $(x,y)_i$

##### Assumptions

Lecture (See slide 23 of LectureD):  

* let $y(t)$ denote the number of events that have occurred during a time interval $[0, t]$
* P1: $y(0) = 0$
* P2: For all $n \geq 0$, and for any two time intervals, $I_1$ and $I_2$, of equal length, Pr($n$ events in $I_1$) = Pr($n$ events in $I_2$)
* P3: Events that occur in nonoverlapping time intervals are mutually independent (want to relax this and replace with exchangeability)
* P4: $\lim\limits_{h \to 0}\frac{\text{Pr}(y(h) > 1)}{h} = 0$
* P5: $0 < \text{Pr}\{y(t)=0\} < 1, ~ \forall ~  t > 0$

Under these conditions, there exists a positive number $\theta$ that produces the density below where $\theta$ = the true underlying death rate in Quentin Taratino movies (measured in bodies per hour)

$$p(y ~|~ \theta) = \frac{1}{y!}(\theta t)^{y}e^{-(\theta t)} \cdot {1}_{\{0,1,2,...\}}(y)$$

Wikipedia:  

* $y$ the number of times an event occurs in an interval and it can take values 0, 1, 2,...
    - Confirmed
* The occurrence of one event does not affect the probability that a second event will occur. That is, events occur independently.
    - LIKELY VIOLATED: if someone gets shot and killed, it is likely (increased probability) that someone else will also die soon either by association or as a result of retaliation.
* The rate at which events occur is constant. The rate cannot be higher in some intervals and lower in other intervals.
    - LIKELY VIOLATED: fight scenes, beginning/end less likely to have deaths than the middle/climax
* Two events cannot occur at exactly the same instant.
    - Technically two people 
* The probability of an event in an interval is proportional to the length of the interval.
    - Seems reasonable: longer movies allow more time for more deaths
    - LIKELY VIOLATED: see plot below, body count does not appear to increase with movie duration

Not an assumption but a result of the sampling distribution: E[$y | \theta$] = Var($y | \theta$) = $\theta$
    
```{r, echo = FALSE}
plot(qt$hours, qt$body.count, ann = FALSE, axes = FALSE, xlim = c(1.5, 3), col = "violetred", pch = 4)
box(col = "gray50", lty = 1)
axis(1, at = seq.int(1.5, 3, 0.5), col = "gray50", lwd = 0, lwd.tick = 1)
axis(2, at = seq.int(0,400,100), col = "gray50", lwd = 0, lwd.tick = 1)
title(xlab = "Movie Duration (hours)", ylab = "Body Count")
```
  
### Likelihood
A necessary and sufficient condition to get product of identical distributions is  
$$p(y_1,...y_n ~|~ s_n) = \frac{s_n!}{y_1!,...,y_n!} \prod\limits_{i=1}^n \left(\frac{1}{n}\right)^{y_i}$$
For every $n$, where $s_n = y_1 + ... + y_n$. Assuming [NEEDS JUSTIFICATION] this condition holds, the likelihood is:

$$\begin{align*}
p(y ~|~ \theta) & \propto \exp\left( -\theta \sum\limits_{i=1}^n t_i \right) ~ \exp\left(\log~\theta \cdot \sum\limits_{i=1}^n y_i\right) \\
& \propto \exp\left( -18.1 \cdot \theta \right) ~ \exp\left(563 \cdot \log~\theta \right) \\
& \propto \theta^{563} e^{ -18.1 \cdot \theta}
\end{align*}$$


    
### Conjugate Prior: Gamma

[Interactive conjugate prior graphic](https://ryan-quigley.shinyapps.io/BDAproject/) using [data](https://figshare.com/articles/On_screen_movie_kill_counts_for_hundreds_of_films/889719) compiled by [Randal Olson](http://www.randalolson.com/) from the site: http://www.moviebodycounts.com/  

After trial and error by visual inspection, the best fit appears to be $\alpha = 1.5$ and $\beta = 1/35.5 = 0.0282$. These numbers are also quite close to the analytical solution:
```{r}
l0 <- 0
u0 <- 200
p0 <- 0.99
m0 <- 17.5
center0 <- "mode"

f <- function(a, m, l, u, center = "mode", p = 0.99) {
  if (center == "mode") b <- (a - 1) / m else
  if (center == "mean") b <- a / m
  pgamma(u, shape = a, rate = b) -
  pgamma(l, shape = a, rate = b) - p
}
a <- uniroot(f, interval = c(1, 5), m = m0,
               l = l0, u = u0,
               center = center0, p = p0)$root
if (center0 == "mode") b <- (a - 1) / m0 else b <- a / m0
cat(paste("a =", round(a,3), "; b =", round(b,3)))
```

$$\begin{align*}
p(\theta ~|~ \alpha = 1.5, \beta = 0.0282) & = \frac{(0.0282)^{1.5}}{\Gamma(1.5)}\theta^{1.5 - 1}e^{-(0.0282)\cdot\theta} \\
& \propto \theta^{1.5 - 1}e^{-(0.0282)\cdot\theta}
\end{align*}$$

```{r, echo = FALSE}
## Genre list for project dataset
qt.g <- unique(unlist(strsplit(paste(qt$genre, collapse = ", ", sep = ""), ", ")))

## Splitting genre list for each movie in death count dataset
dc.g <- strsplit(tolower(dc$Genre), "|", fixed = TRUE)

## Checking if any genres match those of project genre list
dc$Genre_Match <- logical(1)
for (i in seq_along(dc.g)) {
  dc$Genre_Match[i] <- any(dc.g[[i]] %in% qt.g)
}

## Filter death count dataset
## 1) Rating R or Not Rates
## 2) Year later than 1991 (earliest is 1992)
## 3) Genre Match
dc.filt <- dc[dc$MPAA_Rating %in% c("R", "Unrated", "NR") & dc$Year > 1991 & dc$Genre_Match == TRUE, ]
rownames(dc.filt) <- 1:nrow(dc.filt)

h <- 10
alpha <- 1.5
beta <- 1/35.5

d <- density(dc.filt$Body_Count, kernel = "epanechnikov", bw = h, from = 0)
plot(d, ann = FALSE, axes = FALSE,
     xlim = c(-100, 700), ylim = c(0, 0.02), 
     bty = "n", col = "violetred", lwd = 1.5)
axis(1, at = seq.int(-50, 700, 50), labels = NA)
axis(1, at = seq.int(0, 600, 100), lwd = 0, lwd.ticks = 0)
axis(2, at = seq.int(0, 0.02, 0.005), pos = -75)
    
## Gamma parameter controls
g.mean <- alpha/beta
g.mode <- (alpha-1)/beta
g.var <- alpha/(beta)^2

## Plot theoretical gamma distribution
curve(dgamma(x, shape = alpha, rate = beta), from = 0, to = 600, add = TRUE, lty = 2, col = "slateblue")
#legend("top", legend = paste(c("Mean =", "Mode =", "Variance ="), c(g.mean, g.mode, g.var)), bty = "n")
legend("top", legend = c("KDE", "Gamma"), col = c("slateblue", "violetred"), lty = c(2,1), bty = "n")
title(xlab = expression(theta), ylab = "Density", line = 2)
```

### Posterior Distribution  

In general, the posterior distribution is $\text{Gamma}\left(\alpha + \sum\limits_{i=1}^n y_i, \beta + \sum\limits_{i=1}^n t_i\right)$
$$\begin{align*}
p(\theta ~|~ y) & \propto \theta^{563} e^{ -18.1 \cdot \theta} \cdot \theta^{1.5 - 1}e^{-(0.0282)\cdot\theta} \\
& \propto \theta^{564.5 - 1} e^{ -18.1282 \cdot \theta}
\end{align*}$$

Thus, the posterior distribution of $\theta$ is Gamma(564.5, 18.1282)

```{r, echo = FALSE}
t.sum <- sum(qt$hours)
y.sum <- sum(qt$body.count)
alpha.post <- alpha + y.sum
beta.post <- beta + t.sum
curve(dgamma(x, shape = alpha.post, rate = beta.post), from = 0, to = 300, lty = 1, col = "violetred", ann = FALSE, bty = "n")
curve(dgamma(x, shape = alpha, rate = beta), from = 0, to = 300, lty = 2, col = "slateblue", add = TRUE)
legend("top", legend = c("Prior", "Posterior"), col = c("slateblue", "violetred"), lty = c(2,1), bty = "n")
title(xlab = expression(theta), ylab = "Density", line = 2)
```

##### HPD

```{r, echo = FALSE}
library(HDInterval)
p <- 0.99
hpd <- hdi(qgamma, shape = alpha + y.sum, rate = beta + t.sum, credMass = p)
cat("The ", 100*attributes(hpd)$credMass, "% HPD Region for death rate (theta) is: [", paste(round(hpd,2), collapse = ", "), "]", sep = "")
```

### Posterior Predictive Distribution
Do we need to account for $t$ in the prediction?
The posterior predictive distribution for a single additional observation is a negative binomial distribution (see Gelman page 44): NB$\left(y ~|~ \alpha + \sum\limits_{i=1}^n y_i, \beta + \sum\limits_{i=1}^n t_i\right)$

```{r}
post.preds <- dnbinom(0:60, size = alpha.post, prob = (beta.post/(1+beta.post)))
plot(0:60, post.preds, ann = FALSE, type = "h", lty = 3, col = "grey50", bty = "n", axes = FALSE, ylim = c(0, 0.08))
points(0:60, post.preds, pch = 20, col = "violetred")
axis(1, seq.int(0,60,5), col = "gray50")
axis(2, seq.int(0,0.08,0.01), col = "gray50")
title(xlab = expression(tilde(y)), ylab = expression(paste("Pr(", tilde(y), ")", sep = "")))
```

Thus, the most likely values for the body count in Quentin Taratino's next movie are 30 or 31.

### Sensitivity to Prior Parameters

### Posterior Predictive Checking  
The observed data should look plausible under the posterior predictive distribution

```{r}
## Simulation set=up
set.seed(2016)
m <- 100000
n.obs <- length(qt$body.count)
theta.sim <- rgamma(m, shape = alpha.post, rate = beta.post)
yrep <- mapply(rpois, n = n.obs, lambda = theta.sim)
```

##### Maximum

```{r, echo = FALSE}
obs.max <- max(qt$body.count)      # observed maximum
sim.max <- apply(yrep, 2, max)   # simulated maximum
pval <- length(sim.max[sim.max <= obs.max]) / m
hist(sim.max, xlim = c(0,400), freq = FALSE, ann = FALSE)
lines(rep(obs.max, 2), c(0, 0.10), col = "red", lwd = 1.5)
mtext(paste("p-value:",pval), side = 3)
```

**Conclusion**: The maximum of the dataset is inconsistent with our model. [NEED MORE INTERPRETATION/DETAIL]

##### Minimum
```{r, echo = FALSE}
obs.min <- min(qt$body.count)      # observed minimum
sim.min <- apply(yrep, 2, min)   # simulated minimum
pval <- length(sim.min[sim.min >= obs.min]) / m
hist(sim.min, freq = FALSE, xlim = c(0,50), ylim = c(0,0.15), ann = FALSE)
lines(rep(obs.min, 2), c(0, 0.12), col = "red", lwd = 1.5)
mtext(paste("p-value:",pval), side = 3)
```

**Conclusion**: 

##### Sample mean 
```{r, echo = FALSE}

```

**Conclusion**: 

##### Sample variance
```{r, echo = FALSE}

```

**Conclusion**: 

##### Range of data
```{r, echo = FALSE}

```

**Conclusion**: 

##### Ratio: Sample Mean to Sample Variance
```{r, echo = FALSE}

```

**Conclusion**: 
